{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape,train_labels.shape,test_images.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-aca322c5f1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 x = Input(batch_shape=batch_shape,\n\u001b[1;32m    462\u001b[0m                           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                           name=layer.name + '_input')\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# This will build the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m   1453\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m   1456\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m   1362\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                                          name=self.name)\n\u001b[0m\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \"\"\"\n\u001b[1;32m   1676\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_eager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[1;32m   1678\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transforming the data in the form the network expects it to.\n",
    "train_images = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##transform the labels into categorical, since labels are in text form, but the network only deals\n",
    "##with the numbers.\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.2519 - acc: 0.9274\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1018 - acc: 0.9696\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0668 - acc: 0.9799\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0483 - acc: 0.9852\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0372 - acc: 0.9888\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0215 - acc: 0.9940\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0166 - acc: 0.9949\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0125 - acc: 0.9965\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0098 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbdbc999b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,train_labels,epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 74us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy = network.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0714866100803647, 0.9815)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADcNJREFUeJzt3XGolfUdx/HPtzYj7iblvIk5260lAynmxkEH2XJsaYVhCxKlxOCi/WHQYNHCiklU1JgbRTO4WzqrLQ1a6R8xdTK6DYZ4Clda27K4Ms2811rMReWs7/44j3Gre37P6ZznnOfo9/2Cyznn+T7Peb6c+vicc37PeX7m7gIQzyllNwCgHIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQX+jkziZOnOh9fX2d3CUQytDQkA4fPmyNrNtS+M3sMkn3SzpV0m/c/d7U+n19fapWq63sEkBCpVJpeN2m3/ab2amSfiXpcknTJS02s+nNPh+AzmrlM/9MSXvd/XV3Pyppg6QFxbQFoN1aCf8USf8a9Xh/tuwTzGy5mVXNrDoyMtLC7gAUqe3f9rv7gLtX3L3S29vb7t0BaFAr4T8gaeqox1/NlgE4AbQS/p2SppnZuWY2TtIiSZuLaQtAuzU91Ofux8zsRklbVBvqW+vuewrrDEBbtTTO7+7PSHqmoF4AdBCn9wJBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUS7P0mtmQpCOSPpR0zN0rRTQFoP1aCn/me+5+uIDnAdBBvO0Hgmo1/C5pq5k9b2bLi2gIQGe0+rZ/trsfMLOzJG0zs7+7++DoFbJ/FJZL0jnnnNPi7gAUpaUjv7sfyG6HJT0laeYY6wy4e8XdK729va3sDkCBmg6/mfWY2ZeP35c0V9LuohoD0F6tvO2fJOkpMzv+PL939z8W0hWAtms6/O7+uqRvFtgLgA5iqA8IivADQRF+ICjCDwRF+IGgCD8QVBG/6kMX27FjR7L+6KOPJuuDg4PJ+u7dzZ/XtXr16mT97LPPTtafe+65ZH3JkiV1a7NmzUpuGwFHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+k8DGjRvr1m666abktiMjI8m6uyfrc+bMSdYPH65/Yeebb745uW2evN5S+96wYUNL+z4ZcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5+8Cx44dS9Z37tyZrC9btqxu7d13301ue8kllyTrd9xxR7I+e/bsZP2DDz6oW1u4cGFy2y1btiTreSoVZoxP4cgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0HljvOb2VpJ8yUNu/sF2bIJkjZK6pM0JGmhu/+7fW2e3B577LFkvb+/v+nnnjt3brKeuhaAJI0fP77pfec9f6vj+FOnTk3Wly5d2tLzn+waOfL/VtJln1p2q6Tt7j5N0vbsMYATSG743X1Q0tufWrxA0vrs/npJVxXcF4A2a/Yz/yR3P5jdf1PSpIL6AdAhLX/h57ULqdW9mJqZLTezqplV864XB6Bzmg3/ITObLEnZ7XC9Fd19wN0r7l7p7e1tcncAitZs+DdLOv5V6lJJm4ppB0Cn5IbfzB6X9FdJ3zCz/WbWL+leSZea2auSfpA9BnACyR3nd/fFdUrfL7iXk9btt9+erN9zzz3Jupkl6ytWrKhbu+uuu5LbtjqOn+fuu+9u23M/8MADyTofM9M4ww8IivADQRF+ICjCDwRF+IGgCD8QFJfuLsCdd96ZrOcN5Z122mnJ+rx585L1++67r27t9NNPT26b5/3330/Wt27dmqzv27evbi1viu28y4YvWLAgWUcaR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/ga98847dWtr1qxJbpv3k9y8cfynn346WW/F3r17k/Vrr702Wa9Wq03v+5prrknWb7nllqafG/k48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzN+jo0aN1a61OQ5Z3Cerh4boTIkmS1q1bV7e2aVN6PpU9e/Yk60eOHEnW885hOOWU+seX6667LrltT09Pso7WcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByx/nNbK2k+ZKG3f2CbNkqScskHR/gXunuz7SryW4wbty4urWzzjoruW3eOH1fX1+ynjeW3oopU6Yk63lTeL/xxhvJ+sSJE+vWrrzyyuS2aK9Gjvy/lXTZGMt/6e4zsr+TOvjAySg3/O4+KOntDvQCoINa+cx/o5m9aGZrzezMwjoC0BHNhv8hSV+XNEPSQUmr661oZsvNrGpm1VbPgQdQnKbC7+6H3P1Dd/9I0q8lzUysO+DuFXev9Pb2NtsngII1FX4zmzzq4Q8l7S6mHQCd0shQ3+OS5kiaaGb7Jf1U0hwzmyHJJQ1JuqGNPQJog9zwu/viMRY/3IZeutoZZ5xRt5Z3Xf358+cn62+99Vayfv755yfrqXnqr7/++uS2EyZMSNYXLVqUrOeN8+dtj/Jwhh8QFOEHgiL8QFCEHwiK8ANBEX4gKC7dXYBZs2Yl6918WvPg4GCy/uyzzybreT83Pu+88z53T+gMjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/MG99957yXreOH5enZ/0di+O/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8wc2bN6/sFlASjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTuOL+ZTZX0iKRJklzSgLvfb2YTJG2U1CdpSNJCd/93+1pFO2zZsqXsFlCSRo78xyT92N2nS/qOpBVmNl3SrZK2u/s0SduzxwBOELnhd/eD7v5Cdv+IpFckTZG0QNL6bLX1kq5qV5MAive5PvObWZ+kb0naIWmSux/MSm+q9rEAwAmi4fCb2ZckPSnpR+7+n9E1d3fVvg8Ya7vlZlY1s2o3z1kHRNNQ+M3si6oF/3fu/ods8SEzm5zVJ0saHmtbdx9w94q7V3p7e4voGUABcsNvtcuzPizpFXf/xajSZklLs/tLJW0qvj0A7dLIT3ovkrRE0ktmtitbtlLSvZKeMLN+SfskLWxPi2in1157rewWUJLc8Lv7XyTVuzj794ttB0CncIYfEBThB4Ii/EBQhB8IivADQRF+ICgu3R3cxRdfnKzXztzGyYgjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/cBdeeGGyPm3atGQ973oAqTpXdioXR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpxfiStXLkyWe/v7296+wcffDC57fTp05N1tIYjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ElTvOb2ZTJT0iaZIklzTg7veb2SpJyySNZKuudPdn2tUoynH11Vcn6xs2bEjWt23bVre2atWq5Lbr1q1L1nt6epJ1pDVyks8xST929xfM7MuSnjez4/9Ff+nuP29fewDaJTf87n5Q0sHs/hEze0XSlHY3BqC9PtdnfjPrk/QtSTuyRTea2YtmttbMzqyzzXIzq5pZdWRkZKxVAJSg4fCb2ZckPSnpR+7+H0kPSfq6pBmqvTNYPdZ27j7g7hV3r3DNNqB7NBR+M/uiasH/nbv/QZLc/ZC7f+juH0n6taSZ7WsTQNFyw29mJulhSa+4+y9GLZ88arUfStpdfHsA2qWRb/svkrRE0ktmtitbtlLSYjObodrw35CkG9rSIUo1fvz4ZP2JJ55I1m+77ba6tTVr1iS3zRsK5Ce/rWnk2/6/SLIxSozpAycwzvADgiL8QFCEHwiK8ANBEX4gKMIPBGXu3rGdVSoVr1arHdsfEE2lUlG1Wh1raP4zOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFAdHec3sxFJ+0YtmijpcMca+Hy6tbdu7Uuit2YV2dvX3L2h6+V1NPyf2blZ1d0rpTWQ0K29dWtfEr01q6zeeNsPBEX4gaDKDv9AyftP6dbeurUvid6aVUpvpX7mB1Ceso/8AEpSSvjN7DIz+4eZ7TWzW8vooR4zGzKzl8xsl5mV+vvjbBq0YTPbPWrZBDPbZmavZrdjTpNWUm+rzOxA9trtMrMrSuptqpn92cxeNrM9ZnZTtrzU1y7RVymvW8ff9pvZqZL+KelSSfsl7ZS02N1f7mgjdZjZkKSKu5c+Jmxm35X0X0mPuPsF2bKfSXrb3e/N/uE8091/0iW9rZL037Jnbs4mlJk8emZpSVdJul4lvnaJvhaqhNetjCP/TEl73f11dz8qaYOkBSX00fXcfVDS259avEDS+uz+etX+5+m4Or11BXc/6O4vZPePSDo+s3Spr12ir1KUEf4pkv416vF+ddeU3y5pq5k9b2bLy25mDJOyadMl6U1Jk8psZgy5Mzd30qdmlu6a166ZGa+Lxhd+nzXb3b8t6XJJK7K3t13Ja5/Zumm4pqGZmztljJmlP1bma9fsjNdFKyP8ByRNHfX4q9myruDuB7LbYUlPqftmHz50fJLU7Ha45H4+1k0zN481s7S64LXrphmvywj/TknTzOxcMxsnaZGkzSX08Rlm1pN9ESMz65E0V903+/BmSUuz+0slbSqxl0/olpmb680srZJfu66b8drdO/4n6QrVvvF/TdJtZfRQp6/zJP0t+9tTdm+SHlftbeD/VPtupF/SVyRtl/SqpD9JmtBFvT0q6SVJL6oWtMkl9TZbtbf0L0ralf1dUfZrl+irlNeNM/yAoPjCDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP8HF8NDxhA0MHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb89396710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(trn_images,trn_labels),(tst_images,tst_labels) = mnist.load_data()\n",
    "digit = trn_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efb8938f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Manipulating the slices of tensors to select required part of an image\n",
    "my_slice = trn_images[:,14:,14:]\n",
    "m =  my_slice[4]\n",
    "plt.imshow(m,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##selecting the nth batch\n",
    "for n in range(batch_size):\n",
    "    batch = train_images[128 * n:128 * (n + 1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.activations import relu\n",
    "import numpy as np\n",
    "x = np.random.rand(10)\n",
    "W = np.random.rand(10)\n",
    "b = np.random.rand(10)\n",
    "out = relu(np.dot(x,W)+b,alpha=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.75639038, 3.31974055, 2.66731721, 2.69637966, 3.46452235,\n",
       "       2.65637042, 3.02666655, 3.47043283, 3.21883572, 3.01202257])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'define_macros': [('HAVE_CBLAS', None)],\n",
       " 'include_dirs': ['/usr/local/include',\n",
       "  '/usr/include',\n",
       "  '/home/surya/DL/include'],\n",
       " 'language': 'c',\n",
       " 'libraries': ['blas', 'blas'],\n",
       " 'library_dirs': ['/usr/lib']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.distutils.system_info as sysinfo\n",
    "sysinfo.get_info('blas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/surya/DL/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.activations import relu\n",
    "import numpy as np\n",
    "X = np.array([[-0.1,1]])\n",
    "out = relu(X,alpha=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def naive_dot_product(x,y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        z = z + x[i] * y[i]\n",
    "    return z\n",
    "naive_dot_product(np.array([1,2,3]),np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 11.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##naive matrix vector product\n",
    "def naive_matrix_vector_product(x,y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] = z[i] + x[i][j] * y[j]\n",
    "    return z\n",
    "\n",
    "naive_matrix_vector_product(np.array([[1,2],[3,4]]),np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
